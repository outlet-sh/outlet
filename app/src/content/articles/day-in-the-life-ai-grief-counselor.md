---
title: 'A Day in the Life of an AI Grief Counselor'
slug: 'day-in-the-life-ai-grief-counselor'
date: '2025-12-02'
author: 'Alma Tuck'
excerpt: "In late 2024 I ran a quick AI coding walkthrough for senior developers. What followed wasn't about code. It was about fear. In that moment I stopped being a trainer and became an AI grief counselor."
tags: ['AI', 'Leadership', 'Culture', 'Consulting']
featured: true
readTime: '8 min'
---

In late 2024 I was between architecture meetings when I ran my first quick AI coding walkthrough. Nothing formal. Forty-five minutes. The idea was simple. Show the company's senior developers how to use AI inside a twenty-six year old ColdFusion codebase.

I started with a demo. I asked them to give me their top ten items on their technical debt list. No prep. No warning. I picked their number one mess: six different ways to capture contact information, all stitched together in different eras and all needing to be unified.

I cloned their repo, built the prompts, and fixed the whole thing while they watched. I wrote the tests too. It all passed.

They seemed excited. At least that's how the Zoom call felt at the time.

What followed lasted through my entire engagement. It started almost right away.

"Hey Alma, got a sec?" That was the first Slack message.
"When you've got a few minutes can we connect?" came a moment later.

I joined the first call and realized what was happening.

This wasn't about code.

This was about fear.

In that moment I stopped being a trainer and became an AI grief counselor.

"This is going to take our jobs, isn't it?"
"How long till none of us are needed?"
"I'm excited but scared."
"My whole career is over."

You don't get a script for those moments. You answer as honestly as you can. I told them the truth. AI wasn't there yet. Still isn't. But the direction was obvious and the timeline wasn't decades.

That didn't calm anyone.

Panic showed up. Then refusal.

## The Fracture

In the weeks that followed, the team split.

Some leaned in.
Some shut it out.
Some pretended to try it and mocked it when it fell short.

A few insisted this was another hype cycle. It won't be. Anyone paying attention knows that now.

Inside companies, entrenched developers still build walls around the same points.

"Our codebase is too complex."
"AI doesn't understand legacy systems."
"ColdFusion is too old."
"Assembly is too low-level."
"Java is too enterprise."
"C++ is too picky."

They sound like technical objections. They aren't.

They're fear with better vocabulary.

The truth is that AI can handle all of it when someone guides it well. I showed them that in forty-five minutes. Their top technical-debt item. Solved. On the call. With their code.

## A Scene From a Different Era

It reminded me of Hidden Figures. In that film, NASA brings in a new IBM mainframe. The moment it arrives, fear runs through Dorothy Vaughan's group of human computers. They know what it means. A machine that can run more calculations in a second than they can do in a month.

Dorothy tells her team, "It does twenty-four thousand calculations per second," and the room goes silent. One of them mutters, "They'll never get that to work." She doesn't flinch.

"Oh, it'll run eventually. And when it does, we have to know how to program it."

She checks out a FORTRAN book from the library and learns it. Then she teaches her team. That choice secures her future and proves something we keep learning again and again.

Even when the tools get faster and the work changes shape, there is always a human layer the machine can't reach.

AI is the same thing in our time. Some people lean in now, even with the rough edges. Others stand back and wait for some perfect moment when the threat feels less real.

The people who treat it like Dorothy did won't be replaced.
The ones who wait for the machine to define their future are the ones who lose control of it.

## Where the Split Leads

Over the months, the split widened. The ones who leaned in got past the early quirks and rough edges. They figured out how to make the tools work for them. Their output went up. Their stress went down. They were shipping more with less strain, and you could see it in the way they talked about their work.

They weren't trying to protect their past.
They were building their future.

The others tightened around their fear. Their work slowed. Everything became a debate about what AI couldn't do instead of what they could do with it. They weren't bad engineers. They were just stuck in the wrong question.

"What if this replaces us?" becomes a loop you can't escape.

There's a simple truth under all of this.

You can ask "what if" and stay frozen in place.
Or you can say "even if" and move forward anyway.

You don't need blind optimism. You just need to stop waiting for certainty before taking a step.

If a developer recognizes themselves in the fear, I'd tell them what I told the team privately. AI isn't here to erase you, but it will pass you by if you refuse to touch it.

The people who stay valuable aren't the ones who wait for the machine to define their role.
They're the ones who learn enough to direct it.

If any of this feels familiar in your own team, the fracture you're seeing isn't technical. It's human.

And it's shaping your organization's future whether anyone names it or not.
